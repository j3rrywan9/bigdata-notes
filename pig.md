# Pig

##
A data flow indicates the order of operations for processing data.

```
pig -x local
```

```
pig -x mapreduce
```

## Pig Latin Basics

### Relations, Bags, Tuples, Fields
Pig Latin statements work with relations. A relation can be defined as follows:
- A relation is a bag (more specifically, an outer bag).
- A bag is a collection of tuples.
- A tuple is an ordered set of fields.
- A field is a piece of data.

A Pig relation is similar to a table in a relational database, where the tuples in the bag correspond to the rows in a table.

Also note that relations are unordered which means there is no guarantee that tuples are processed in any particular order.

### Data Types
chararray

Character array (string) in Unicode UTF-8 format.

### Schemas
Schemas enable you to assign names to fields and declare types for fields. Schemas are optional but we encourage you to use them whenever possible; type declarations result in better parse-time error checking and more efficient code execution.

### LOAD
Loads data from the file system.

Syntax
```
LOAD 'data' [USING function] [AS schema]
```

'data' The name of the file or directory, in single quotes.

USING Keyword.

If the USING clause is omitted, the default load function PigStorage is used.

function The load function.
- You can use a built in function.
- You can write your own load function if your data is in a format that cannot be processed by the built in functions.

AS Keyword.

schema A schema using the AS keyword, enclosed in parentheses.

The loader produces the data of the type specified by the schema. If the data does not conform to the schema, depending on the loader, either a null value or an error is generated.

Usage

Use the LOAD operator to load data from the file system.

### FILTER
Selects tuples from a relation based on some condition.

Syntax
```
alias = FILTER alias BY expression;
```

alias

The name of the relation.

BY

Required keyword.

expression

A boolean expression.

Usage

Use the FILTER operator to work with tuples or rows of data (if you want to work with columns of data, use the FOREACH...GERNERATE operation).

FILTER is commonly used to select the data that you want; or, conversely, to filter out (remove) the data you don't want.

### FOREACH
Generates data transformation based on columns of data.

Syntax
```
alias = FOREACH { block | nested_block };
```

alias

The name of relation (outer bag).

block

FOREACH...GENERATE block used with a relation (outer bag).

### GROUP
Groups the data in one or more relations.

Usage

The GROUP operator groups together tuples that have the same group key (key field). The key field will be a tuple if the group key has more than one field, otherwise it will be the same type as that of the group key. The result of a GROUP operation is a relation that includes one tuple per group. This tuple contains two fields:
- The first field is named "group" and is the same type as the group key.
- The second field takes the name of the original relation and is type bag.
- The names of both fields are generated by the system.

### TOKENIZE
Splits a string and outputs a bag of words.

Syntax
```
TOKENIZE(expression)
```

Usage

Use the TOKENIZE function to split a string of words (all words in a single tuple) into a bag of words (each word in a single tuple).

## Quiz
Set up input files in HDFS if you use mapreduce
```
hdfs dfs -mkdir /user/cloudera/pigin
hdfs dfs -put /home/cloudera/testfile* /user/cloudera/pigin
```
Set up an output folder in HDFS if you use mapreduce
```
hdfs dfs -mkdir /user/cloudera/pigoutnew
```
Clean up output folder before rerun
```
hdfs dfs -rm /user/cloudera/pigoutnew/word_counts_pig/*
hdfs dfs -rmdir /user/cloudera/pigoutnew/word_counts_pig/
```
